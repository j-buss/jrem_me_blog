---
title: "Chapter 3 - Probability Distributions and Probability Densities"
author: Jeremy Buss
output: html_document
date: "2022-06-07"
categories:
  - John E. Freund's Mathematical Statistics with Applications - Miller/Miller
  - Statistics
draft: yes
katex: yes
---



<div id="random-variables" class="section level2">
<h2>3.1 Random Variables</h2>
<p><strong>Random Variable</strong> - If <span class="math inline">\(S\)</span> is a sample space with a probability measure and <span class="math inline">\(X\)</span> is a real-valued function defined over the elements of <span class="math inline">\(S\)</span>, then <span class="math inline">\(X\)</span> is called a <strong>random variable</strong></p>
<p><strong>Discrete Random Variables</strong> - random variables whose range is finite or contably infinite</p>
</div>
<div id="probability-distributions" class="section level2">
<h2>3.2 Probability Distributions</h2>
<p><strong>Probability Distribution</strong> - If <span class="math inline">\(X\)</span> is a discrete random variable, the function given by <span class="math inline">\(f(x)=P(X=x)\)</span> for each <span class="math inline">\(x\)</span> within the range of <span class="math inline">\(X\)</span> is called the <strong>probability distribution</strong> of <span class="math inline">\(X\)</span></p>
<p><strong>Theorem 3.1</strong> - A function can serve as the probability distribution of a discrete random variable <span class="math inline">\(X\)</span> if and only if its values, <span class="math inline">\(f(x)\)</span>, satisfy the conditions:
1. <span class="math inline">\(f(x) \ge 0\)</span> for each value within its domain;
2. <span class="math inline">\(\sum_{x} f(x)=1\)</span>, where the summation extends over all the values within its domain.</p>
<p><strong>Distribution Function</strong> - If <span class="math inline">\(X\)</span> is a discrete random variable, the function given by</p>
<p><span class="math display">\[
\begin{align}
F(x)=P(X \le x) = \sum_{t \le X} f(t) &amp;&amp; \text{for} \,-\infty \lt x \lt \infty
\end{align}
\]</span></p>
<p>where <span class="math inline">\(f(t)\)</span> is the value of the probability distribution of <span class="math inline">\(X\)</span> at <span class="math inline">\(t\)</span>, is called the <strong>distribution function</strong>, or the <strong>cumulative distribution</strong> of <span class="math inline">\(X\)</span></p>
<p><strong>Theorem 3.2</strong> The values <span class="math inline">\(F(x)\)</span> of the distribution function of a discrete random variable <span class="math inline">\(X\)</span> satisfy the conditions:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(F(- \infty ) = 0\)</span> and <span class="math inline">\(F(\infty) = 1\)</span>;</li>
<li>if <span class="math inline">\(a \lt b\)</span>, then <span class="math inline">\(F(a) \le F(b)\)</span> for any real numbers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span></li>
</ol>
<p><strong>Theorem 3.3</strong> - If the range of a random variable <span class="math inline">\(X\)</span> consists of the values <span class="math inline">\(x_1 \lt x_2 \lt x_3 \lt \cdots \lt x_n\)</span>, then <span class="math inline">\(f(x_1)=F(x_1)\)</span> and</p>
<p><span class="math display">\[
\begin{align}
f(x_i)=F(x_i)-F(x_{i-1}) &amp;&amp; \text{for} \; i = 2,3,\ldots,n
\end{align}
\]</span></p>
</div>
<div id="continuous-random-variables" class="section level2">
<h2>3.3 Continuous Random Variables</h2>
</div>
<div id="probability-density-functions" class="section level2">
<h2>3.4 Probability Density Functions</h2>
<p><strong>Probability Density Function</strong> - A function with values <span class="math inline">\(f(x)\)</span>, defined over the set of all real numbers, is called a <strong>probability density function</strong> or abreviated as <strong>p.d.f.</strong> of the continuous random variable <span class="math inline">\(X\)</span> if and only if</p>
<p><span class="math display">\[
P(a \le X \le b) = \int_a^b f(x)dx
\]</span></p>
<p>for any real constants <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> with <span class="math inline">\(a \le b\)</span></p>
<p><strong>Theorem 3.4</strong> - If <span class="math inline">\(X\)</span> is a continuous random variable and <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are real constants with <span class="math inline">\(a \le b\)</span>, then</p>
<p><span class="math display">\[
P(a \le X \le b) = P(a \le X \lt b) = P(a \lt X \le b) = P(a \lt X \lt b)
\]</span></p>
<p><strong>Theorem 3.5</strong> - A function can serve as a probability density of a continuous random variable <span class="math inline">\(X\)</span> if its values, <span class="math inline">\(f(x)\)</span>, satisfy the conditions:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(f(x) \ge 0\)</span> for <span class="math inline">\(- \infty \lt x \lt \infty\)</span></li>
<li><span class="math inline">\(\int_{-\infty}^{\infty} f(x) dx = 1\)</span></li>
</ol>
<p><strong>Distribution Function</strong> - If <span class="math inline">\(X\)</span> is a continuous random variable and the value of its probability density at <span class="math inline">\(t\)</span> is <span class="math inline">\(f(t)\)</span>, then the function given by</p>
<p><span class="math display">\[
\begin{align}
F(x)=P(X \le x)= \int_{- \infty}^{x} f(t) dt &amp;&amp; \text{for} \, -\infty \lt x \lt \infty
\end{align}
\]</span></p>
<p><strong>Theorem 3.6</strong> - If <span class="math inline">\(f(x)\)</span> and <span class="math inline">\(F(x)\)</span> are the values of the probability density and the distribution function of <span class="math inline">\(X\)</span> at <span class="math inline">\(x\)</span>, then</p>
<p><span class="math display">\[
P(a \le X \le b) = F(b)-F(a)
\]</span></p>
<p>for any real constants <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> with <span class="math inline">\(a \le b\)</span>, and</p>
<p><span class="math display">\[
f(x)=\frac{dF(x)}{dx}
\]</span></p>
<p>where the derivative exists.</p>
</div>
<div id="multivariate-distributions" class="section level2">
<h2>3.5 Multivariate Distributions</h2>
<p><strong>bivariate</strong> - situations where we are interested at the same time in a pair of random variables defined over a joint sample space</p>
<p><strong>multivariate</strong> - situations covering any finite number of random variables</p>
<p><strong>univariate</strong> - situations with one random variable</p>
<p><strong>Joint Probability Distribution</strong> - If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are discrete random variables, the function given by <span class="math inline">\(f(x,y)=P(X=x,Y=y)\)</span> for each pair of values <span class="math inline">\((x,y)\)</span> within the range of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is called the <strong>joint probability distribution</strong> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p>
<p><strong>Theorem 3.7</strong> - A bivariate function can serve as the joint probability distribution of a pair of discrete random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> if and only if its values, <span class="math inline">\(f(x,y)\)</span>, satisfy the conditions:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(f(x,y) \ge 0\)</span> for each pair of values <span class="math inline">\((x,y)\)</span> within its domain</li>
<li><span class="math inline">\(\sum_x \sum_y f(x,y)=1\)</span>, where the double summation extends over all possible pairs <span class="math inline">\((x,y)\)</span> within its domain</li>
</ol>
<p><strong>Joint Distribution Function</strong> If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are discrete random variables, the function given by</p>
<p><span class="math display">\[
\begin{align}
F(x,y)=P(X \le x, Y \le y) = \sum_{s \le x} \sum_{t \le y} f(s,t) &amp;&amp; \text{for} \, - \infty \lt x \lt \infty\\
&amp;&amp; \text{for} \, - \infty \lt y \lt \infty
\end{align}
\]</span></p>
<p>where <span class="math inline">\(f(s,t)\)</span> is the value of the joint probablity distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> at <span class="math inline">\((s,t)\)</span>, is called the <strong>joint distribution function</strong> or the <strong>joint cumulative distribution</strong> of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p>
<p><strong>Joint Probability Density Function</strong> - A bivariate function with values <span class="math inline">\(f(x,y)\)</span> defined over the <span class="math inline">\(xy\)</span>-plane is called a <strong>joint probability density function</strong> of the continuous random variables <span class="math inline">\(X\)</span> <span class="math inline">\(Y\)</span> if and only if</p>
<p><span class="math display">\[
P(X,Y) \in A = \underset{A}\iint f(x,y)dxdy
\]</span></p>
<p>for any region <span class="math inline">\(A\)</span> in the <span class="math inline">\(xy\)</span>-plane</p>
<p><strong>Theorem 3.8</strong> - A bivariate function can serve as a joint probability density function of a pair of continuous random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> if its values, <span class="math inline">\(f(x,y)\)</span>, satisfy the conditions:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(f(x,y) \geq 0\)</span> for <span class="math inline">\(- \infty \lt x \lt \infty\)</span>, <span class="math inline">\(- \infty \lt y \lt \infty\)</span></li>
<li><span class="math inline">\(\int^\infty_{-\infty} \int^\infty_{-\infty} f(x,y) dx dy = 1\)</span></li>
</ol>
<p><strong>Joint Distribution Function</strong> - If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are continuous random variables, the function given by</p>
<p><span class="math display">\[
\begin{align}
F(x,y)=P(X \le x, Y \e y)= \int^\infty_{-\infty} \int^\infty_{-\infty} f(s,t) ds dt &amp;&amp; \text{for} -\infty \lt x \lt \infty\\
&amp;&amp;-\infty \lt y \lt \infty\\
\end{align}
\]</span></p>
<p>where <span class="math inline">\(f(s,t)\)</span> is the joint probablity density of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> at <span class="math inline">\((s,t)\)</span>, is called the <strong>joint distribution function of X and Y</strong></p>
</div>
<div id="marginal-distributions" class="section level2">
<h2>3.6 Marginal Distributions</h2>
<p><strong>Marginal Distribution</strong> - If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are discrete random variables and <span class="math inline">\(f(x,y)\)</span> is the value of their joint probability distribution at <span class="math inline">\((x,y)\)</span>, the function given by</p>
<p><span class="math display">\[
g(x)=\underset{y}\sum f(x,y)
\]</span></p>
<p>for each <span class="math inline">\(x\)</span> within the range of <span class="math inline">\(X\)</span> is called the **marginal distribution of X). Correspondingly, the function given by</p>
<p><span class="math display">\[
h(y)=\underset{x}\sum f(x,y)
\]</span></p>
<p>for each <span class="math inline">\(y\)</span> within the range of <span class="math inline">\(Y\)</span> is called the **marginal distribution of <span class="math inline">\(Y\)</span></p>
<p><strong>Marginal Density</strong> - If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are continuous random variables and <span class="math inline">\(f(x,y)\)</span> is the value of their joint probability density ad <span class="math inline">\(x,y)\)</span>, the function given by</p>
<p><span class="math display">\[
\begin{align}
g(x)= \int_{-\infty}^{\infty} f(x,y)dy &amp;&amp; \text{for} -\infty \lt x \lt \infty\\
\end{align}
\]</span></p>
<p>is called the <strong>marginal density of <span class="math inline">\(X\)</span></strong>. Correspondingly, the function given by</p>
<p><span class="math display">\[
\begin{align}
h(x)= \int_{-\infty}^{\infty} f(x,y)dx &amp;&amp; \text{for} -\infty \lt y \lt \infty\\
\end{align}
\]</span></p>
<p>is called the <strong>marginal density of <span class="math inline">\(Y\)</span></strong>.</p>
</div>
<div id="conditional-distributions" class="section level2">
<h2>3.7 Conditional Distributions</h2>
<p><strong>Conditional Distribution</strong> - If <span class="math inline">\(f(x,y)\)</span> is the value of the joint probability distribution of the discrete random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> at <span class="math inline">\((x,y)\)</span> and <span class="math inline">\(h(y)\)</span> is the value of the marginal distribution of <span class="math inline">\(Y\)</span> at <span class="math inline">\(y\)</span>, the function given by</p>
<p><span class="math display">\[
\begin{align}
f(x|y)=\frac{f(x,y)}{h(y)} &amp;&amp; h(y) \ne 0
\end{align}
\]</span></p>
<p>for each <span class="math inline">\(x\)</span> within the range of <span class="math inline">\(X\)</span> is called the <strong>conditional distribution of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span></strong>. Correspondingly, if <span class="math inline">\(g(x)\)</span> is the value of the marginal distribution of <span class="math inline">\(X\)</span> at <span class="math inline">\(x\)</span>, the function given by</p>
<p><span class="math display">\[
\begin{align}
w(x|y)=\frac{f(x,y)}{g(y)} &amp;&amp; g(y) \ne 0
\end{align}
\]</span></p>
<p>for each <span class="math inline">\(y\)</span> within the range of <span class="math inline">\(Y\)</span> is called the <strong>conditional distribution of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span></strong>.</p>
<p><strong>Conditional Density</strong> - If <span class="math inline">\(f(x,y)\)</span> is the value of the joint density of the continuous random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> at <span class="math inline">\((x,y)\)</span> and <span class="math inline">\(h(y)\)</span> is the value of the marginal distribution of <span class="math inline">\(Y\)</span> at <span class="math inline">\(y\)</span>, the function given by</p>
<p><span class="math display">\[
\begin{align}
f(x|y)=\frac{f(x,y)}{h(y)} &amp;&amp; h(y) \ne 0
\end{align}
\]</span></p>
<p>for <span class="math inline">\(-\infty \lt x \lt \infty\)</span>, is called the <strong>conditional density of <span class="math inline">\(X\)</span> given <span class="math inline">\(Y=y\)</span></strong>. Correspondingly, if <span class="math inline">\(g(x)\)</span> is the value of the marginal density of <span class="math inline">\(X\)</span> at <span class="math inline">\(x\)</span>, the function given by</p>
<p><span class="math display">\[
\begin{align}
w(x|y)=\frac{f(x,y)}{g(y)} &amp;&amp; g(y) \ne 0
\end{align}
\]</span></p>
<p>for <span class="math inline">\(-\infty \lt y \lt \infty\)</span>, is called the <strong>conditional density of <span class="math inline">\(Y\)</span> given <span class="math inline">\(X=x\)</span></strong>.</p>
<p><strong>Independence of Discrete Random Variables</strong> - If <span class="math inline">\(f(x_1,x_2,\ldots , x_n)\)</span> is the value of the joint probability distribution of the discrete random variables <span class="math inline">\(X_1, X_2, \ldots, X_n\)</span> at <span class="math inline">\((x_1, x_2, \ldots x_n)\)</span> and <span class="math inline">\(f_i(x_i)\)</span> is the value of the marginal distribution of <span class="math inline">\(X_i\)</span> at <span class="math inline">\(x_i\)</span> for <span class="math inline">\(i=1,2,\ldots,n\)</span>, then <span class="math inline">\(n\)</span> random variables are <strong>independent</strong> if and only if</p>
<p><span class="math display">\[
f(x_1,x_2,\ldots,x_n)=f_1(x_1)\cdot f_2(x_2)\cdot \ldots f_n(x_n)
\]</span></p>
<p>for all <span class="math inline">\((x_1, x_2, \ldots, x_n)\)</span> within their range
## 3.8 Theory in Practice</p>
<p><strong>Frequency Distribution</strong> - A grouping of numerical data into classes having definite upper and lower limits</p>
<p><strong>stem-and-leaf display</strong> - device for presenting quantitative data similar to histogram; generally grouped in 10s</p>
<p><strong>positive skewness</strong> - long right-hand tail</p>
<p><strong>negative skewness</strong> - long left-hand tail</p>
<p><strong>mode</strong> - the value that appears most frequently in a data set; in a histogram it may be less general and refer to data values that are high points where the mode is a bar in a histogram that is surrounded by bars of lower frequency</p>
<p><strong>bimodal</strong> - histogram exibiting two modes</p>
<p><strong>multimodal</strong> - histogram exhibiting more than two modes</p>
</div>
